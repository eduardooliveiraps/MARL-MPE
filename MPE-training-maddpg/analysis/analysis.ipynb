{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_tag = pd.read_csv('../data/training_data_simple_tag.csv')\n",
    "df_simple_reference = pd.read_csv('../data/training_data_simple_reference.csv')\n",
    "df_simple_crypto = pd.read_csv('../data/training_data_simple_crypto.csv')\n",
    "df_simple_reference_iddpg = pd.read_csv('../data/training_data_simple_reference_iddpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_optimiser_steps</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>episode_reward_mean_adversary</th>\n",
       "      <th>episode_reward_mean_agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration       lr  train_batch_size  gamma  n_optimiser_steps  \\\n",
       "0          0  0.00001               128   0.99                100   \n",
       "1          1  0.00001               128   0.99                100   \n",
       "2          2  0.00001               128   0.99                100   \n",
       "3          3  0.00001               128   0.99                100   \n",
       "4          4  0.00001               128   0.99                100   \n",
       "\n",
       "   max_grad_norm  episode_reward_mean_adversary  episode_reward_mean_agent  \n",
       "0            1.0                            7.0                       -7.0  \n",
       "1            1.0                            1.0                       -1.0  \n",
       "2            1.0                           46.0                      -46.0  \n",
       "3            1.0                          202.0                     -202.0  \n",
       "4            1.0                            1.0                       -1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_optimiser_steps</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>episode_reward_mean_agents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-203.774765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.758026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-264.652893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-281.747101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-311.593201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration       lr  train_batch_size  gamma  n_optimiser_steps  \\\n",
       "0          0  0.00001                10   0.99                100   \n",
       "1          1  0.00001                10   0.99                100   \n",
       "2          2  0.00001                10   0.99                100   \n",
       "3          3  0.00001                10   0.99                100   \n",
       "4          4  0.00001                10   0.99                100   \n",
       "\n",
       "   max_grad_norm  episode_reward_mean_agents  \n",
       "0            1.0                 -203.774765  \n",
       "1            1.0                 -199.758026  \n",
       "2            1.0                 -264.652893  \n",
       "3            1.0                 -281.747101  \n",
       "4            1.0                 -311.593201  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_optimiser_steps</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>episode_reward_mean_eve</th>\n",
       "      <th>episode_reward_mean_bob</th>\n",
       "      <th>episode_reward_mean_alice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-177.394928</td>\n",
       "      <td>5.616959</td>\n",
       "      <td>5.616959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.222626</td>\n",
       "      <td>-4.082033</td>\n",
       "      <td>-4.082033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.683899</td>\n",
       "      <td>-3.731676</td>\n",
       "      <td>-3.731676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-131.066467</td>\n",
       "      <td>-18.625031</td>\n",
       "      <td>-18.625031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-121.291733</td>\n",
       "      <td>-20.719635</td>\n",
       "      <td>-20.719635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration       lr  train_batch_size  gamma  n_optimiser_steps  \\\n",
       "0          0  0.00001                10   0.99                100   \n",
       "1          1  0.00001                10   0.99                100   \n",
       "2          2  0.00001                10   0.99                100   \n",
       "3          3  0.00001                10   0.99                100   \n",
       "4          4  0.00001                10   0.99                100   \n",
       "\n",
       "   max_grad_norm  episode_reward_mean_eve  episode_reward_mean_bob  \\\n",
       "0            1.0              -177.394928                 5.616959   \n",
       "1            1.0              -156.222626                -4.082033   \n",
       "2            1.0              -156.683899                -3.731676   \n",
       "3            1.0              -131.066467               -18.625031   \n",
       "4            1.0              -121.291733               -20.719635   \n",
       "\n",
       "   episode_reward_mean_alice  \n",
       "0                   5.616959  \n",
       "1                  -4.082033  \n",
       "2                  -3.731676  \n",
       "3                 -18.625031  \n",
       "4                 -20.719635  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple_crypto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_optimiser_steps</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>episode_reward_mean_agents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-231.936005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-244.498688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-280.064850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-375.338165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-443.447327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration       lr  train_batch_size  gamma  n_optimiser_steps  \\\n",
       "0          0  0.00001                10   0.99                100   \n",
       "1          1  0.00001                10   0.99                100   \n",
       "2          2  0.00001                10   0.99                100   \n",
       "3          3  0.00001                10   0.99                100   \n",
       "4          4  0.00001                10   0.99                100   \n",
       "\n",
       "   max_grad_norm  episode_reward_mean_agents  \n",
       "0            1.0                 -231.936005  \n",
       "1            1.0                 -244.498688  \n",
       "2            1.0                 -280.064850  \n",
       "3            1.0                 -375.338165  \n",
       "4            1.0                 -443.447327  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple_reference_iddpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
